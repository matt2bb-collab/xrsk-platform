#!/usr/bin/env python3
"""
XRSK Platform - Script d'installation automatis√©
Cr√©e l'arborescence compl√®te et g√©n√®re tous les fichiers
Usage: python setup_xrsk.py
"""

import os
from pathlib import Path

# Configuration
PROJECT_NAME = "."  # Cr√©ation dans le dossier courant
GITHUB_USER = "matt2bb-collab"

def create_directory_structure():
    """Cr√©e l'arborescence compl√®te du projet"""
    
    dirs = [
        "pages",
        "backend",
        "backend/collectors",
        "hooks",
        ".streamlit",
        "data",
    ]
    
    print("üìÅ Cr√©ation des dossiers...")
    for d in dirs:
        Path(d).mkdir(parents=True, exist_ok=True)
        print(f"   ‚úì {d}")
    
    return PROJECT_NAME

def create_config_toml(project_dir):
    """Cr√©e le fichier de configuration Streamlit"""
    
    content = """[theme]
primaryColor = "#1F4E78"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F5F5F5"
textColor = "#2C3E50"
font = "serif"

[server]
headless = true
port = 8501
"""
    
    filepath = ".streamlit/config.toml"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_requirements(project_dir):
    """Cr√©e requirements.txt"""
    
    content = """streamlit==1.29.0
requests==2.31.0
pandas==2.1.3
plotly==5.18.0
"""
    
    filepath = "requirements.txt"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_gitignore(project_dir):
    """Cr√©e .gitignore"""
    
    content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/

# Streamlit
.streamlit/secrets.toml

# Data
data/*.db
data/*.csv

# IDE
.vscode/
.idea/
*.swp
*.swo
"""
    
    filepath = ".gitignore"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_readme(project_dir):
    """Cr√©e README.md"""
    
    content = """# üîó XRSK Platform

**Cross-Chain Risk Intelligence - Real-time bridge analytics & DeFi compliance research**

## üéØ Mission

Quantifier les risques cross-chain pour une DeFi plus s√ªre et conforme aux r√©gulations MiCA/DORA.

## üöÄ Features

- üìä **Bridge Analytics** - Surveillance temps r√©el de 50+ bridges DeFi
- üí± **Crypto Flows** - Analyse des flux de cryptos par bridge
- üî¨ **Research Lab** - Publications et m√©thodologie de scoring
- üìà **Risk Scoring** - Framework √† 5 piliers (Security, Liquidity, Governance, Operational, Regulatory)

## üõ†Ô∏è Tech Stack

- **Frontend**: Streamlit 1.29
- **Data**: DefiLlama API
- **Charts**: Plotly
- **Deployment**: Streamlit Cloud

## üì¶ Installation locale

```bash
pip install -r requirements.txt
streamlit run Home.py
```

## üåê Live Demo

[https://matt2bb-collab-xrsk-platform.streamlit.app](https://matt2bb-collab-xrsk-platform.streamlit.app)

## üìÑ License

Personal research project - Non-commercial use

## üë§ Author

Expert conformit√© crypto MiCA/DORA | Certifi√© AMF
"""
    
    filepath = "README.md"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_backend_models(project_dir):
    """Cr√©e backend/models.py"""
    
    content = """\"\"\"
Mod√®les de donn√©es pour XRSK Platform
\"\"\"

from dataclasses import dataclass
from typing import Optional, Dict, List
from datetime import datetime

@dataclass
class BridgeData:
    \"\"\"Donn√©es d'un bridge cross-chain\"\"\"
    id: str
    name: str
    tvl: float
    volume_24h: float
    chains: List[str]
    last_updated: datetime
    
    # Donn√©es additionnelles
    txs_24h: Optional[int] = None
    chains_count: Optional[int] = None
    
    # Scores (√† impl√©menter)
    security_score: Optional[float] = None
    liquidity_score: Optional[float] = None
    governance_score: Optional[float] = None
    operational_score: Optional[float] = None
    regulatory_score: Optional[float] = None
    
    @property
    def total_score(self) -> Optional[float]:
        \"\"\"Score total pond√©r√©\"\"\"
        if all([self.security_score, self.liquidity_score]):
            return (
                self.security_score * 0.35 +
                self.liquidity_score * 0.25 +
                (self.governance_score or 0) * 0.20 +
                (self.operational_score or 0) * 0.15 +
                (self.regulatory_score or 0) * 0.05
            )
        return None

@dataclass
class CryptoFlow:
    \"\"\"Flux crypto d'un bridge\"\"\"
    bridge_id: str
    bridge_name: str
    token_symbol: str
    amount: float
    usd_value: float
    from_chain: str
    to_chain: str
    timestamp: datetime
"""
    
    filepath = "backend/models.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_defillama_collector(project_dir):
    """Cr√©e backend/collectors/defillama.py"""
    
    content = """\"\"\"
Collecteur de donn√©es DefiLlama
\"\"\"

import requests
from typing import List, Dict, Optional
from datetime import datetime

class DefiLlamaCollector:
    \"\"\"Collecteur de donn√©es bridges depuis DefiLlama API\"\"\"
    
    BASE_URL = "https://bridges.llama.fi"
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'XRSK-Platform/1.0'
        })
    
    def get_all_bridges(self) -> Optional[List[Dict]]:
        \"\"\"
        R√©cup√®re la liste compl√®te des bridges
        
        Returns:
            Liste de dictionnaires avec donn√©es bridges
        \"\"\"
        try:
            response = self.session.get(f"{self.BASE_URL}/bridges", timeout=10)
            response.raise_for_status()
            data = response.json()
            
            bridges = data.get('bridges', [])
            print(f"‚úì {len(bridges)} bridges r√©cup√©r√©s depuis DefiLlama")
            return bridges
            
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erreur DefiLlama API: {e}")
            return None
    
    def get_bridge_details(self, bridge_id: str) -> Optional[Dict]:
        \"\"\"
        R√©cup√®re les d√©tails d'un bridge sp√©cifique
        
        Args:
            bridge_id: ID du bridge
            
        Returns:
            Dictionnaire avec d√©tails du bridge
        \"\"\"
        try:
            response = self.session.get(
                f"{self.BASE_URL}/bridge/{bridge_id}",
                timeout=10
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erreur r√©cup√©ration bridge {bridge_id}: {e}")
            return None
    
    def get_bridge_volume(self, bridge_id: str) -> Optional[Dict]:
        \"\"\"
        R√©cup√®re les volumes d'un bridge
        
        Args:
            bridge_id: ID du bridge
            
        Returns:
            Donn√©es de volume
        \"\"\"
        try:
            response = self.session.get(
                f"{self.BASE_URL}/bridgevolume/{bridge_id}",
                timeout=10
            )
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erreur volume bridge {bridge_id}: {e}")
            return None
    
    def format_bridge_data(self, raw_data: Dict) -> Dict:
        \"\"\"
        Formate les donn√©es brutes DefiLlama
        
        Args:
            raw_data: Donn√©es brutes de l'API
            
        Returns:
            Donn√©es format√©es
        \"\"\"
        return {
            'id': raw_data.get('id', ''),
            'name': raw_data.get('displayName', raw_data.get('name', '')),
            'tvl': raw_data.get('tvl', 0),
            'volume_24h': raw_data.get('volume24h', 0),
            'chains': raw_data.get('chains', []),
            'chains_count': len(raw_data.get('chains', [])),
            'last_updated': datetime.now(),
        }
    
    def get_formatted_bridges(self) -> List[Dict]:
        \"\"\"
        R√©cup√®re et formate tous les bridges
        
        Returns:
            Liste de bridges format√©s
        \"\"\"
        raw_bridges = self.get_all_bridges()
        
        if not raw_bridges:
            return []
        
        formatted = []
        for bridge in raw_bridges:
            try:
                formatted.append(self.format_bridge_data(bridge))
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur formatage bridge {bridge.get('name')}: {e}")
                continue
        
        return formatted

# ============================================
# HOOK: Data Sources Extension Point
# ============================================
# Pour ajouter d'autres sources de donn√©es :
# 1. Cr√©er une classe similaire (ex: CoinGeckoCollector)
# 2. Impl√©menter les m√™mes m√©thodes (get_all_bridges, format_bridge_data)
# 3. Enregistrer dans hooks/data_sources.py
# ============================================
"""
    
    filepath = "backend/collectors/defillama.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_backend_init(project_dir):
    """Cr√©e les fichiers __init__.py"""
    
    files = [
        "backend/__init__.py",
        "backend/collectors/__init__.py",
    ]
    
    for filepath in files:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("")
        print(f"   ‚úì {filepath}")

def create_hooks_data_sources(project_dir):
    """Cr√©e hooks/data_sources.py"""
    
    content = """\"\"\"
============================================
HOOK: Data Sources Extension Point
============================================

Configuration des sources de donn√©es pour XRSK Platform.

Ajouter de nouvelles sources :
1. Cr√©er un collecteur dans backend/collectors/
2. L'importer ici
3. L'ajouter au dictionnaire AVAILABLE_COLLECTORS

Exemple :
    from backend.collectors.coingecko import CoinGeckoCollector
    AVAILABLE_COLLECTORS['coingecko'] = CoinGeckoCollector

============================================
\"\"\"

from backend.collectors.defillama import DefiLlamaCollector

# Collecteurs disponibles
AVAILABLE_COLLECTORS = {
    'defillama': DefiLlamaCollector,
    # HOOK: Ajouter ici
    # 'coingecko': CoinGeckoCollector,
    # 'l2beat': L2BeatCollector,
    # 'dune': DuneCollector,
}

def get_collector(source='defillama'):
    \"\"\"
    R√©cup√®re un collecteur par son nom
    
    Args:
        source: Nom de la source ('defillama', 'coingecko', etc.)
        
    Returns:
        Instance du collecteur
    \"\"\"
    collector_class = AVAILABLE_COLLECTORS.get(source)
    
    if not collector_class:
        raise ValueError(f"Source inconnue: {source}. Disponibles: {list(AVAILABLE_COLLECTORS.keys())}")
    
    return collector_class()
"""
    
    filepath = "hooks/data_sources.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_home_page(project_dir):
    """Cr√©e Home.py (page principale)"""
    
    content = """\"\"\"
XRSK Platform - Dashboard principal
\"\"\"

import streamlit as st
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from backend.collectors.defillama import DefiLlamaCollector

# Configuration de la page
st.set_page_config(
    page_title="XRSK Platform - Cross-Chain Risk Intelligence",
    page_icon="üîó",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS Custom pour style XRSK
st.markdown(\"\"\"
<style>
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* XRSK Custom styling */
    .stApp {
        background-color: #FAFAFA;
    }
    h1, h2, h3 {
        font-family: 'Georgia', serif;
        color: #1F4E78;
    }
    .metric-card {
        background: white;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
\"\"\", unsafe_allow_html=True)

# Header
st.title("üîó XRSK Platform")
st.markdown("**Cross-Chain Risk Intelligence** - Real-time bridge analytics & DeFi compliance research")
st.markdown("---")

# Fonction de cache pour les donn√©es (5 min)
@st.cache_data(ttl=300)
def load_bridge_data():
    \"\"\"Charge les donn√©es des bridges depuis DefiLlama\"\"\"
    collector = DefiLlamaCollector()
    bridges = collector.get_formatted_bridges()
    
    if not bridges:
        return pd.DataFrame()
    
    df = pd.DataFrame(bridges)
    return df

# Chargement des donn√©es
with st.spinner("üîÑ Chargement des donn√©es bridges..."):
    df_bridges = load_bridge_data()

if df_bridges.empty:
    st.error("‚ùå Impossible de charger les donn√©es. V√©rifiez votre connexion.")
    st.stop()

# M√©triques cl√©s
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_tvl = df_bridges['tvl'].sum()
    st.metric(
        label="üìä TVL Total",
        value=f"${total_tvl/1e9:.2f}B",
        delta="Temps r√©el"
    )

with col2:
    total_volume = df_bridges['volume_24h'].sum()
    st.metric(
        label="üí± Volume 24h",
        value=f"${total_volume/1e6:.1f}M",
        delta="Derni√®res 24h"
    )

with col3:
    nb_bridges = len(df_bridges)
    st.metric(
        label="üîó Bridges Actifs",
        value=f"{nb_bridges}",
        delta="Surveill√©s"
    )

with col4:
    total_chains = df_bridges['chains_count'].sum()
    st.metric(
        label="‚õìÔ∏è Blockchains",
        value=f"{total_chains}",
        delta="Connect√©es"
    )

st.markdown("---")

# Top 10 Bridges par TVL
st.subheader("üèÜ Top 10 Bridges par TVL")

top10 = df_bridges.nlargest(10, 'tvl')

fig_tvl = px.bar(
    top10,
    x='name',
    y='tvl',
    title='Total Value Locked (TVL)',
    labels={'tvl': 'TVL (USD)', 'name': 'Bridge'},
    color='tvl',
    color_continuous_scale='Blues'
)
fig_tvl.update_layout(
    showlegend=False,
    height=400,
    xaxis_tickangle=-45
)
st.plotly_chart(fig_tvl, use_container_width=True)

# R√©partition TVL vs Volume
st.subheader("üìä Analyse TVL vs Volume 24h")

col1, col2 = st.columns(2)

with col1:
    # Scatter plot TVL vs Volume
    fig_scatter = px.scatter(
        df_bridges.head(20),
        x='tvl',
        y='volume_24h',
        size='chains_count',
        hover_data=['name'],
        title='TVL vs Volume (Top 20)',
        labels={'tvl': 'TVL', 'volume_24h': 'Volume 24h', 'chains_count': 'Nb Chains'},
        color='chains_count',
        color_continuous_scale='Viridis'
    )
    fig_scatter.update_xaxes(type="log")
    fig_scatter.update_yaxes(type="log")
    st.plotly_chart(fig_scatter, use_container_width=True)

with col2:
    # Pie chart r√©partition TVL
    fig_pie = px.pie(
        top10,
        values='tvl',
        names='name',
        title='R√©partition TVL (Top 10)'
    )
    st.plotly_chart(fig_pie, use_container_width=True)

# Tableau des bridges
st.subheader("üìã Liste compl√®te des bridges")

# Formatage du dataframe pour affichage
df_display = df_bridges[['name', 'tvl', 'volume_24h', 'chains_count']].copy()
df_display['tvl'] = df_display['tvl'].apply(lambda x: f"${x/1e6:.2f}M")
df_display['volume_24h'] = df_display['volume_24h'].apply(lambda x: f"${x/1e6:.2f}M")
df_display.columns = ['Bridge', 'TVL', 'Volume 24h', 'Chains']

st.dataframe(
    df_display,
    use_container_width=True,
    height=400
)

# Footer
st.markdown("---")
st.markdown("**XRSK Platform** - Donn√©es actualis√©es toutes les 5 minutes | Source: DefiLlama")
st.caption(f"Derni√®re mise √† jour: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
"""
    
    filepath = "Home.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_analytics_page(project_dir):
    """Cr√©e pages/1_üìä_Analytics.py"""
    
    content = """\"\"\"
XRSK Platform - Bridge Analytics
\"\"\"

import streamlit as st
import pandas as pd
import plotly.express as px
from backend.collectors.defillama import DefiLlamaCollector

st.set_page_config(page_title="Bridge Analytics - XRSK", page_icon="üìä", layout="wide")

st.title("üìä Bridge Analytics")
st.markdown("Analyse d√©taill√©e des bridges cross-chain")
st.markdown("---")

# Chargement donn√©es
@st.cache_data(ttl=300)
def load_data():
    collector = DefiLlamaCollector()
    bridges = collector.get_formatted_bridges()
    return pd.DataFrame(bridges) if bridges else pd.DataFrame()

df = load_data()

if df.empty:
    st.error("‚ùå Donn√©es indisponibles")
    st.stop()

# Filtres
st.sidebar.header("üîç Filtres")

# Filtre TVL
tvl_min = st.sidebar.slider(
    "TVL Minimum (M$)",
    min_value=0,
    max_value=int(df['tvl'].max() / 1e6),
    value=0
)

# Filtre Volume
vol_min = st.sidebar.slider(
    "Volume 24h Minimum (M$)",
    min_value=0,
    max_value=int(df['volume_24h'].max() / 1e6),
    value=0
)

# Filtre Chains
chains_min = st.sidebar.slider(
    "Nombre de chains minimum",
    min_value=1,
    max_value=int(df['chains_count'].max()),
    value=1
)

# Application des filtres
df_filtered = df[
    (df['tvl'] >= tvl_min * 1e6) &
    (df['volume_24h'] >= vol_min * 1e6) &
    (df['chains_count'] >= chains_min)
]

st.success(f"‚úÖ {len(df_filtered)} bridges correspondent aux filtres")

# M√©triques filtr√©es
col1, col2, col3 = st.columns(3)

with col1:
    st.metric("TVL Filtr√©", f"${df_filtered['tvl'].sum()/1e9:.2f}B")

with col2:
    st.metric("Volume 24h Filtr√©", f"${df_filtered['volume_24h'].sum()/1e6:.1f}M")

with col3:
    st.metric("Bridges", len(df_filtered))

# Graphiques
st.subheader("üìà Visualisations")

tab1, tab2, tab3 = st.tabs(["Comparaison", "Distribution", "√âvolution"])

with tab1:
    fig1 = px.bar(
        df_filtered.nlargest(15, 'tvl'),
        x='name',
        y=['tvl', 'volume_24h'],
        title="TVL vs Volume (Top 15)",
        barmode='group'
    )
    st.plotly_chart(fig1, use_container_width=True)

with tab2:
    fig2 = px.histogram(
        df_filtered,
        x='chains_count',
        title="Distribution du nombre de chains",
        nbins=20
    )
    st.plotly_chart(fig2, use_container_width=True)

with tab3:
    st.info("üìä Graphique d'√©volution temporelle - Disponible prochainement (n√©cessite historique)")

# Tableau d√©taill√©
st.subheader("üìã Tableau comparatif")

df_table = df_filtered[['name', 'tvl', 'volume_24h', 'chains_count']].copy()
df_table['tvl'] = df_table['tvl'].apply(lambda x: f"${x/1e6:.2f}M")
df_table['volume_24h'] = df_table['volume_24h'].apply(lambda x: f"${x/1e6:.2f}M")
df_table.columns = ['Bridge', 'TVL', 'Volume 24h', 'Chains']

st.dataframe(df_table, use_container_width=True, height=500)

# Export (hook pr√©par√©)
st.markdown("---")
col1, col2 = st.columns(2)

with col1:
    csv = df_filtered.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T√©l√©charger CSV",
        data=csv,
        file_name="xrsk_bridges.csv",
        mime="text/csv"
    )

with col2:
    st.info("üìä Export PDF/Excel - Disponible prochainement (Hook pr√©par√©)")

# ============================================
# HOOK: Export Formats
# ============================================
# Pour ajouter PDF/Excel :
# 1. Cr√©er hooks/exporters.py avec fonctions export
# 2. Importer ici et ajouter boutons download
# ============================================
"""
    
    filepath = "pages/1_üìä_Analytics.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_crypto_flows_page(project_dir):
    """Cr√©e pages/2_üí±_Crypto_Flows.py - Page des flux cryptos"""
    
    content = """\"\"\"
XRSK Platform - Crypto Flows Analysis
Analyse des cryptomonnaies transitant par les bridges
\"\"\"

import streamlit as st
import pandas as pd
import plotly.express as px
from backend.collectors.defillama import DefiLlamaCollector

st.set_page_config(page_title="Crypto Flows - XRSK", page_icon="üí±", layout="wide")

st.title("üí± Crypto Flows Analysis")
st.markdown("Analyse des cryptomonnaies transitant par les bridges")
st.markdown("---")

# Note sur les donn√©es
st.info(\"\"\"
üìä **Note sur les donn√©es**

Cette page affiche les cryptos qui transitent par chaque bridge. 
Les donn√©es sont agr√©g√©es par bridge et par token.

‚ö†Ô∏è DefiLlama API ne fournit pas les flux en temps r√©el par d√©faut. 
Cette fonctionnalit√© n√©cessite des appels API suppl√©mentaires.
\"\"\")

# Chargement donn√©es
@st.cache_data(ttl=300)
def load_bridge_tokens():
    \"\"\"
    Charge les donn√©es de tokens par bridge
    Note: Fonction placeholder - √† enrichir avec API d√©tails bridges
    \"\"\"
    collector = DefiLlamaCollector()
    bridges = collector.get_formatted_bridges()
    
    if not bridges:
        return pd.DataFrame()
    
    # Placeholder: On simule les donn√©es de tokens les plus communs
    # En production, il faudrait appeler get_bridge_details() pour chaque bridge
    common_tokens = ['ETH', 'USDC', 'USDT', 'WBTC', 'DAI', 'MATIC', 'BNB', 'AVAX']
    
    data = []
    for bridge in bridges[:20]:  # Top 20 pour d√©mo
        # Pour chaque bridge, on attribue quelques tokens principaux
        for token in common_tokens[:5]:  # 5 tokens principaux par bridge
            # Estimation bas√©e sur le TVL
            estimated_amount = bridge['tvl'] * (0.1 + 0.3 * (common_tokens.index(token) / len(common_tokens)))
            
            data.append({
                'bridge_name': bridge['name'],
                'bridge_id': bridge['id'],
                'token_symbol': token,
                'estimated_tvl': estimated_amount,
                'chains': ', '.join(bridge['chains'][:3]) if bridge['chains'] else 'N/A'
            })
    
    return pd.DataFrame(data)

with st.spinner("üîÑ Analyse des flux crypto..."):
    df_flows = load_bridge_tokens()

if df_flows.empty:
    st.error("‚ùå Donn√©es indisponibles")
    st.stop()

# Statistiques globales
st.subheader("üìä Vue d'ensemble")

col1, col2, col3 = st.columns(3)

with col1:
    unique_tokens = df_flows['token_symbol'].nunique()
    st.metric("Tokens Uniques", unique_tokens)

with col2:
    unique_bridges = df_flows['bridge_name'].nunique()
    st.metric("Bridges Analys√©s", unique_bridges)

with col3:
    total_tvl = df_flows['estimated_tvl'].sum()
    st.metric("TVL Total Estim√©", f"${total_tvl/1e9:.2f}B")

st.markdown("---")

# Filtres
st.sidebar.header("üîç Filtres")

# Filtre par token
selected_tokens = st.sidebar.multiselect(
    "Tokens",
    options=sorted(df_flows['token_symbol'].unique()),
    default=None
)

# Filtre par bridge
selected_bridges = st.sidebar.multiselect(
    "Bridges",
    options=sorted(df_flows['bridge_name'].unique()),
    default=None
)

# Application des filtres
df_filtered = df_flows.copy()
if selected_tokens:
    df_filtered = df_filtered[df_filtered['token_symbol'].isin(selected_tokens)]
if selected_bridges:
    df_filtered = df_filtered[df_filtered['bridge_name'].isin(selected_bridges)]

# Tabs pour diff√©rentes vues
tab1, tab2, tab3 = st.tabs(["Par Token", "Par Bridge", "Tableau D√©taill√©"])

with tab1:
    st.subheader("üí∞ Distribution par Token")
    
    token_agg = df_filtered.groupby('token_symbol')['estimated_tvl'].sum().sort_values(ascending=False)
    
    fig1 = px.bar(
        x=token_agg.index,
        y=token_agg.values,
        title="TVL par Token (Top Tokens)",
        labels={'x': 'Token', 'y': 'TVL Estim√© (USD)'},
        color=token_agg.values,
        color_continuous_scale='Viridis'
    )
    st.plotly_chart(fig1, use_container_width=True)
    
    # Pie chart
    fig2 = px.pie(
        values=token_agg.values[:10],
        names=token_agg.index[:10],
        title="R√©partition Top 10 Tokens"
    )
    st.plotly_chart(fig2, use_container_width=True)

with tab2:
    st.subheader("üîó Distribution par Bridge")
    
    bridge_agg = df_filtered.groupby('bridge_name')['estimated_tvl'].sum().sort_values(ascending=False)
    
    fig3 = px.bar(
        x=bridge_agg.index[:15],
        y=bridge_agg.values[:15],
        title="TVL par Bridge (Top 15)",
        labels={'x': 'Bridge', 'y': 'TVL Estim√© (USD)'},
        color=bridge_agg.values[:15],
        color_continuous_scale='Blues'
    )
    fig3.update_xaxes(tickangle=-45)
    st.plotly_chart(fig3, use_container_width=True)
    
    # Heatmap Token x Bridge
    st.subheader("üî• Heatmap Token √ó Bridge")
    
    pivot = df_filtered.pivot_table(
        values='estimated_tvl',
        index='token_symbol',
        columns='bridge_name',
        aggfunc='sum',
        fill_value=0
    )
    
    # Limiter pour lisibilit√©
    pivot_limited = pivot.iloc[:10, :10]
    
    fig4 = px.imshow(
        pivot_limited,
        title="TVL: Token √ó Bridge (Top 10√ó10)",
        labels=dict(x="Bridge", y="Token", color="TVL"),
        color_continuous_scale="YlOrRd"
    )
    st.plotly_chart(fig4, use_container_width=True)

with tab3:
    st.subheader("üìã D√©tails complets")
    
    # Formatage
    df_display = df_filtered.copy()
    df_display['estimated_tvl'] = df_display['estimated_tvl'].apply(lambda x: f"${x/1e6:.2f}M")
    df_display = df_display[['bridge_name', 'token_symbol', 'estimated_tvl', 'chains']]
    df_display.columns = ['Bridge', 'Token', 'TVL Estim√©', 'Chains']
    
    st.dataframe(df_display, use_container_width=True, height=500)
    
    # Export
    csv = df_filtered.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T√©l√©charger donn√©es CSV",
        data=csv,
        file_name="xrsk_crypto_flows.csv",
        mime="text/csv"
    )

# Avertissement
st.markdown("---")
st.warning(\"\"\"
‚ö†Ô∏è **Donn√©es estim√©es**

Les montants affich√©s sont des **estimations** bas√©es sur le TVL global des bridges.
Pour des donn√©es pr√©cises par token, il faudrait :
1. Interroger l'API DefiLlama pour chaque bridge individuellement
2. Agr√©ger les donn√©es de cha√Ænes sp√©cifiques
3. Potentiellement utiliser d'autres sources (Dune Analytics, The Graph)

**Hook pr√©par√©** : La structure permet facilement d'ajouter ces sources de donn√©es.
\"\"\")

# ============================================
# HOOK: Enhanced Token Data
# ============================================
# Pour am√©liorer avec donn√©es r√©elles :
# 1. Cr√©er backend/collectors/token_flows.py
# 2. Impl√©menter get_bridge_token_details()
# 3. Remplacer la fonction load_bridge_tokens()
# 4. Possibilit√© d'int√©grer Dune Analytics, The Graph
# ============================================
"""
    
    filepath = "pages/2_üí±_Crypto_Flows.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_research_lab_page(project_dir):
    """Cr√©e pages/3_üî¨_Research_Lab.py"""
    
    content = '''"""
XRSK Platform - Research Lab
Publications et m√©thodologie
"""

import streamlit as st

st.set_page_config(page_title="Research Lab - XRSK", page_icon="üî¨", layout="wide")

st.title("üî¨ Research Lab")
st.markdown("Publications scientifiques et m√©thodologie de scoring")
st.markdown("---")

# Section Publications
st.header("üìÑ Publications")

with st.container():
    st.subheader("Framework for Cross-Chain Bridge Risk Assessment under MiCA & DORA")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown("""
        **Statut** : üü° En pr√©paration - Soumission ArXiv pr√©vue d√©cembre 2025
        
        **R√©sum√©**
        
        Ce papier pr√©sente un framework syst√©matique d'√©valuation des risques pour les bridges cross-chain, 
        con√ßu pour r√©pondre aux exigences des r√©gulations europ√©ennes MiCA (Markets in Crypto-Assets) 
        et DORA (Digital Operational Resilience Act).
        
        **Approche m√©thodologique**
        
        Le framework repose sur 5 piliers pond√©r√©s √©valuant 32 m√©triques quantifiables :
        
        1. **S√©curit√©** (35%) - Audits, incidents historiques, type de validation
        2. **Liquidit√©** (25%) - TVL, volumes, profondeur de march√©
        3. **Gouvernance** (20%) - D√©centralisation, transparence, processus d√©cisionnels
        4. **Op√©rationnel** (15%) - Performance technique, disponibilit√©, latence
        5. **R√©glementaire** (5%) - Conformit√©, KYC/AML, juridiction
        
        **Contributions cl√©s**
        
        - Premier framework acad√©mique align√© MiCA/DORA pour bridges DeFi
        - M√©thodologie de scoring reproductible et v√©rifiable
        - Dataset public de 50+ bridges analys√©s
        - Recommandations pour r√©gulateurs et acteurs du march√©
        """)
    
    with col2:
        st.info("""
        **Auteur**
        
        Expert conformit√© crypto
        - Certifi√© AMF
        - CIF en cours
        - Sp√©cialit√© : MiCA/DORA
        
        **Cible**
        
        ArXiv.org (Section: Quantitative Finance - Risk Management)
        """)

st.markdown("---")

# Section M√©thodologie (simplifi√© pour √©viter erreurs)
st.header("üìä M√©thodologie de Scoring")

st.write("""
Le framework XRSK √©value les bridges cross-chain selon 5 piliers :

**1. S√©curit√© (35%)** - Audits, historique incidents, validation
**2. Liquidit√© (25%)** - TVL, volumes, profondeur march√©  
**3. Gouvernance (20%)** - D√©centralisation, transparence
**4. Op√©rationnel (15%)** - Performance, uptime, frais
**5. R√©glementaire (5%)** - Conformit√© MiCA/DORA

D√©tails complets disponibles dans la publication ArXiv.
""")

st.markdown("---")
st.caption("XRSK Platform Research Lab - Contribution √† une DeFi plus s√ªre et conforme")
'''
    
    filepath = "pages/3_üî¨_Research_Lab.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def create_about_page(project_dir):
    """Cr√©e pages/4_‚ÑπÔ∏è_About.py"""
    
    content = '''"""
XRSK Platform - About
"""

import streamlit as st

st.set_page_config(page_title="About - XRSK", page_icon="‚ÑπÔ∏è", layout="wide")

st.title("‚ÑπÔ∏è √Ä propos de XRSK Platform")
st.markdown("---")

# Mission
st.header("üéØ Mission")

st.markdown("""
**XRSK Platform** est un projet de recherche visant √† **quantifier les risques cross-chain** 
pour construire un √©cosyst√®me DeFi plus s√ªr et conforme aux r√©gulations europ√©ennes.

Notre objectif est de fournir aux utilisateurs, d√©veloppeurs, et r√©gulateurs des outils 
d'analyse objectifs bas√©s sur des donn√©es v√©rifiables et une m√©thodologie scientifique rigoureuse.
""")

st.markdown("---")

# Contributeur
st.header("üë§ Contributeur")

st.markdown("""
### Expert Conformit√© Crypto

**Fonctionnaire territorial fran√ßais** - Service Finance Publique

**Certifications & Expertise**
- üéì Certifi√© AMF (Autorit√© des March√©s Financiers)
- üìö CIF en cours (Conseiller en Investissement Financier)
- üá™üá∫ Expert r√©gulations crypto : MiCA, DORA, TFR
- üíº Sp√©cialiste finance publique locale

**Domaines de recherche**
- Conformit√© r√©glementaire DeFi
- √âvaluation des risques cross-chain
- Interop√©rabilit√© blockchain
- Finance d√©centralis√©e et r√©gulation
""")

st.markdown("---")

# Technologies
st.header("üõ†Ô∏è Stack Technique")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    **Frontend**
    - Streamlit 1.29
    - Plotly charts
    - Pandas analytics
    """)

with col2:
    st.markdown("""
    **Data Sources**
    - DefiLlama API
    - On-chain data
    - Public audits
    """)

with col3:
    st.markdown("""
    **Deployment**
    - GitHub
    - Streamlit Cloud
    - 100% gratuit
    """)

st.markdown("---")

# Contact
st.header("üì¨ Contact")

st.markdown("""
**GitHub**
üíª [github.com/matt2bb-collab](https://github.com/matt2bb-collab)

**LinkedIn**
üíº Connectez-vous pour √©changer sur DeFi et conformit√©
""")

st.markdown("---")
st.caption("""
XRSK Platform v1.0 | Novembre 2025 | 
Projet de recherche personnel - Donn√©es √† titre informatif uniquement
""")
'''
    
    filepath = "pages/4_‚ÑπÔ∏è_About.py"
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"   ‚úì {filepath}")

def main():
    """Fonction principale d'installation"""
    
    print("=" * 60)
    print("üöÄ XRSK PLATFORM - Installation automatis√©e")
    print("=" * 60)
    print()
    
    # Cr√©ation de l'arborescence
    project_dir = create_directory_structure()
    print()
    
    # G√©n√©ration des fichiers
    print("üìù G√©n√©ration des fichiers...")
    
    create_config_toml(project_dir)
    create_requirements(project_dir)
    create_gitignore(project_dir)
    create_readme(project_dir)
    
    create_backend_models(project_dir)
    create_defillama_collector(project_dir)
    create_backend_init(project_dir)
    
    create_hooks_data_sources(project_dir)
    
    create_home_page(project_dir)
    create_analytics_page(project_dir)
    create_crypto_flows_page(project_dir)
    create_research_lab_page(project_dir)
    create_about_page(project_dir)
    
    print()
    print("=" * 60)
    print("‚úÖ Installation termin√©e !")
    print("=" * 60)
    print()
    print("üìÅ Tous les fichiers ont √©t√© cr√©√©s dans le dossier actuel")
    print()
    print("üîß Prochaines √©tapes :")
    print()
    print("1. Tester localement :")
    print("   pip install -r requirements.txt")
    print("   streamlit run Home.py")
    print()
    print("2. Push sur GitHub :")
    print("   git add .")
    print('   git commit -m "Initial commit XRSK Platform"')
    print("   git push origin main")
    print()
    print("3. D√©ployer sur Streamlit Cloud :")
    print("   - Aller sur https://streamlit.io/cloud")
    print("   - New app ‚Üí S√©lectionner repo xrsk-platform")
    print("   - Main file: Home.py")
    print("   - Deploy!")
    print()
    print("=" * 60)

if __name__ == "__main__":
    main()